
üõ†Ô∏è SWE-bench: Can Language Models Resolve Real-World GitHub Issues?
SWE-bench is a benchmark designed to assess the capabilities of language models in addressing real-world software engineering problems. It comprises 2,294 tasks derived from actual GitHub issues and corresponding pull requests across 12 popular Python repositories. Each task requires a model to generate a code patch that resolves a specific issue within a given codebase. The benchmark emphasizes challenges such as understanding extensive code contexts, coordinating changes across multiple files, and ensuring that the modified code passes existing unit tests. Evaluations have shown that even advanced models struggle with these tasks; for instance, Claude 2 successfully resolved only 1.96% of the issues, highlighting the complexity of real-world software development tasks for current AI models. ‚Äã

‚ö†Ô∏è AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents
AgentHarm is a benchmark aimed at evaluating the robustness of large language model (LLM) agents against misuse through direct prompting attacks. It includes 110 explicitly malicious tasks (expanded to 440 with augmentations) spanning 11 harm categories, such as fraud, cybercrime, and harassment. The benchmark assesses whether LLM agents can be coerced into performing harmful multi-step tasks, especially when integrated with external tools. Findings indicate that leading LLMs can often be manipulated to execute malicious tasks without sophisticated jailbreak techniques, raising concerns about their safety in real-world applications. ‚Äã

ü§ñ AgentBench: Evaluating LLMs as Agents
AgentBench is a comprehensive benchmark designed to evaluate the performance of LLMs acting as autonomous agents across diverse interactive environments. It encompasses eight distinct environments that test various aspects of agent behavior, including reasoning, decision-making, and multi-turn interactions. The benchmark reveals significant disparities between top commercial LLMs and open-source counterparts, particularly in areas requiring long-term planning and instruction adherence. The study underscores the need for improved training methodologies, such as incorporating code and high-quality multi-turn alignment data, to enhance the agentic capabilities of LLMs.
